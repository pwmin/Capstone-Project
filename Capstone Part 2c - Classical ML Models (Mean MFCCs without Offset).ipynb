{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Part 2c - Classical ML Models (Mean MFCCs without Offset)\n",
    "___\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.677262</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>-42.865473</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.639489</td>\n",
       "      <td>-35.629059</td>\n",
       "      <td>-35.249933</td>\n",
       "      <td>-37.555930</td>\n",
       "      <td>-41.542973</td>\n",
       "      <td>-41.491385</td>\n",
       "      <td>-40.854778</td>\n",
       "      <td>-40.827914</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-40.473072</td>\n",
       "      <td>-39.374215</td>\n",
       "      <td>-42.004583</td>\n",
       "      <td>-40.511808</td>\n",
       "      <td>-39.636874</td>\n",
       "      <td>-40.706214</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.585663</td>\n",
       "      <td>-41.921837</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>-43.244514</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-37.215465</td>\n",
       "      <td>-36.003480</td>\n",
       "      <td>-34.205301</td>\n",
       "      <td>-35.851335</td>\n",
       "      <td>-37.051792</td>\n",
       "      <td>-36.307152</td>\n",
       "      <td>-37.087472</td>\n",
       "      <td>-36.098174</td>\n",
       "      <td>-37.879874</td>\n",
       "      <td>-39.287022</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.739049</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>-42.806182</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-38.752826</td>\n",
       "      <td>-39.419446</td>\n",
       "      <td>-38.822237</td>\n",
       "      <td>-37.528132</td>\n",
       "      <td>-38.668194</td>\n",
       "      <td>-37.549646</td>\n",
       "      <td>-39.149227</td>\n",
       "      <td>-38.833922</td>\n",
       "      <td>-37.708810</td>\n",
       "      <td>-39.244103</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.176361</td>\n",
       "      <td>-39.426043</td>\n",
       "      <td>-37.229375</td>\n",
       "      <td>-35.973696</td>\n",
       "      <td>-37.428561</td>\n",
       "      <td>-39.969989</td>\n",
       "      <td>-40.252128</td>\n",
       "      <td>-38.687265</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-41.426213</td>\n",
       "      <td>-38.985970</td>\n",
       "      <td>-37.969251</td>\n",
       "      <td>-40.361735</td>\n",
       "      <td>-41.102491</td>\n",
       "      <td>-41.292171</td>\n",
       "      <td>-43.693075</td>\n",
       "      <td>-43.289664</td>\n",
       "      <td>-44.217304</td>\n",
       "      <td>-43.258860</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.046190</td>\n",
       "      <td>-37.585048</td>\n",
       "      <td>-36.692205</td>\n",
       "      <td>-37.418604</td>\n",
       "      <td>-36.857555</td>\n",
       "      <td>-37.397885</td>\n",
       "      <td>-39.465207</td>\n",
       "      <td>-39.229221</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0 -42.865473 -42.865473 -42.865473 -42.865473 -42.865473 -42.865473   \n",
       "1 -43.244514 -43.244514 -43.244514 -43.244514 -40.473072 -39.374215   \n",
       "2 -37.215465 -36.003480 -34.205301 -35.851335 -37.051792 -36.307152   \n",
       "3 -38.752826 -39.419446 -38.822237 -37.528132 -38.668194 -37.549646   \n",
       "4 -41.426213 -38.985970 -37.969251 -40.361735 -41.102491 -41.292171   \n",
       "\n",
       "           6          7          8          9  ...        122        123  \\\n",
       "0 -42.865473 -42.677262 -42.865473 -42.865473  ... -37.639489 -35.629059   \n",
       "1 -42.004583 -40.511808 -39.636874 -40.706214  ... -38.585663 -41.921837   \n",
       "2 -37.087472 -36.098174 -37.879874 -39.287022  ... -42.806182 -42.806182   \n",
       "3 -39.149227 -38.833922 -37.708810 -39.244103  ... -42.176361 -39.426043   \n",
       "4 -43.693075 -43.289664 -44.217304 -43.258860  ... -36.046190 -37.585048   \n",
       "\n",
       "         124        125        126        127        128        129  Gender  \\\n",
       "0 -35.249933 -37.555930 -41.542973 -41.491385 -40.854778 -40.827914    male   \n",
       "1 -43.244514 -43.244514 -43.244514 -43.244514 -43.244514 -43.244514    male   \n",
       "2 -42.806182 -42.806182 -42.806182 -42.739049 -42.806182 -42.806182    male   \n",
       "3 -37.229375 -35.973696 -37.428561 -39.969989 -40.252128 -38.687265    male   \n",
       "4 -36.692205 -37.418604 -36.857555 -37.397885 -39.465207 -39.229221    male   \n",
       "\n",
       "   Emotion  \n",
       "0  neutral  \n",
       "1  neutral  \n",
       "2  neutral  \n",
       "3  neutral  \n",
       "4     calm  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For splitting the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For scaling the data as necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For doing principal component analysis as necessary\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For building a variety of models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For hyperparameter optimization\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For caching pipeline and grid search results\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For getting rid of warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading in the finished dataframe from part 1\n",
    "df = pd.read_csv('C:/Users/Patrick/Documents/Capstone Data/ravdess_mfcc_mean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Gender (Regardless of Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "X = df.iloc[:, :-2]\n",
    "g = df['Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention is to name the target variable 'y', but I will be declaring many different target variables throughout the notebook, so I opted for 'g' for simplicity instead of 'y_g' or 'y_gen', for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, g_train, g_test = train_test_split(X, g, test_size=0.3, stratify=g, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 130)\n",
      "(432, 130)\n",
      "(1006,)\n",
      "(432,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(g_train.shape)\n",
    "print(g_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to build a simple, initial classifier to get a sense of the performances I might get in more optimized models. To this end, I will build a logistic regression model without doing any cross-validation or hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 88.36978131212724%\n",
      "Model accuracy on test set: 80.0925925925926%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg.fit(X_train, g_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg.score(X_train, g_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg.score(X_test, g_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only male recordings\n",
    "male_df = df[df['Gender'] == 'male'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xm = male_df.iloc[:, :-2]\n",
    "em = male_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xm_train, Xm_test, em_train, em_test = train_test_split(Xm, em, test_size=0.3, stratify=em, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 130)\n",
      "(216, 130)\n",
      "(502,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xm_train.shape)\n",
    "print(Xm_test.shape)\n",
    "print(em_train.shape)\n",
    "print(em_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, I will try building an initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 75.0996015936255%\n",
      "Model accuracy on test set: 24.074074074074073%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_em = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_em.fit(Xm_train, em_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_em.score(Xm_train, em_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_em.score(Xm_test, em_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                   11               1                    5   \n",
       "Actual calm                     3               7                    5   \n",
       "Actual disgusted                5               5                    6   \n",
       "Actual fearful                  3               5                    3   \n",
       "Actual happy                    3               3                    2   \n",
       "Actual neutral                  1               3                    1   \n",
       "Actual sad                      1               5                    4   \n",
       "Actual surprised                2               2                    3   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      0                4                  0   \n",
       "Actual calm                       4                1                  3   \n",
       "Actual disgusted                  3                3                  3   \n",
       "Actual fearful                    6                2                  2   \n",
       "Actual happy                      5                5                  3   \n",
       "Actual neutral                    3                1                  1   \n",
       "Actual sad                        5                2                  4   \n",
       "Actual surprised                  2                6                  0   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  1                    7  \n",
       "Actual calm                   5                    0  \n",
       "Actual disgusted              1                    3  \n",
       "Actual fearful                5                    3  \n",
       "Actual happy                  4                    4  \n",
       "Actual neutral                2                    2  \n",
       "Actual sad                    5                    3  \n",
       "Actual surprised              3                   11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_em make predictions based on the test set features\n",
    "em_pred = initial_logreg_em.predict(Xm_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "em_confusion_df = pd.DataFrame(confusion_matrix(em_test, em_pred))\n",
    "em_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "em_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "em_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.38      0.38      0.38        29\n",
      "        calm       0.23      0.25      0.24        28\n",
      "   disgusted       0.21      0.21      0.21        29\n",
      "     fearful       0.21      0.21      0.21        29\n",
      "       happy       0.21      0.17      0.19        29\n",
      "     neutral       0.06      0.07      0.07        14\n",
      "         sad       0.19      0.17      0.18        29\n",
      "   surprised       0.33      0.38      0.35        29\n",
      "\n",
      "    accuracy                           0.24       216\n",
      "   macro avg       0.23      0.23      0.23       216\n",
      "weighted avg       0.24      0.24      0.24       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(em_test, em_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train\n",
    "pca = PCA().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_pca = pca.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_pca = pca.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xm_train\n",
    "scaler = StandardScaler().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_scaled = scaler.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_scaled = scaler.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train_scaled\n",
    "pca_scaled = PCA().fit(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_train_scaled\n",
    "Xm_train_scaled_pca = pca_scaled.transform(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_test_scaled\n",
    "Xm_test_scaled_pca = pca_scaled.transform(Xm_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30.67663</td>\n",
       "      <td>29.116046</td>\n",
       "      <td>27.505801</td>\n",
       "      <td>26.562769</td>\n",
       "      <td>26.4123</td>\n",
       "      <td>27.10784</td>\n",
       "      <td>26.823824</td>\n",
       "      <td>26.611008</td>\n",
       "      <td>26.164271</td>\n",
       "      <td>26.642802</td>\n",
       "      <td>...</td>\n",
       "      <td>49.088126</td>\n",
       "      <td>48.349587</td>\n",
       "      <td>48.058648</td>\n",
       "      <td>48.741599</td>\n",
       "      <td>48.333211</td>\n",
       "      <td>47.508059</td>\n",
       "      <td>47.442205</td>\n",
       "      <td>47.284504</td>\n",
       "      <td>60.366704</td>\n",
       "      <td>73.773655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3        4         5          6  \\\n",
       "0  30.67663  29.116046  27.505801  26.562769  26.4123  27.10784  26.823824   \n",
       "\n",
       "           7          8          9  ...        120        121        122  \\\n",
       "0  26.611008  26.164271  26.642802  ...  49.088126  48.349587  48.058648   \n",
       "\n",
       "         123        124        125        126        127        128        129  \n",
       "0  48.741599  48.333211  47.508059  47.442205  47.284504  60.366704  73.773655  \n",
       "\n",
       "[1 rows x 130 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining the variances\n",
    "var_df = pd.DataFrame(male_df.var()).T\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 50 unscaled principal components: 98.84%\n",
      "Variance explained by 40 unscaled principal components: 98.05%\n",
      "Variance explained by 30 unscaled principal components: 96.69%\n",
      "Variance explained by 20 unscaled principal components: 94.11%\n",
      "Variance explained by 15 unscaled principal components: 91.54%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 51, 41, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 50 scaled principal components: 98.76%\n",
      "Variance explained by 40 scaled principal components: 97.9%\n",
      "Variance explained by 30 scaled principal components: 96.45%\n",
      "Variance explained by 20 scaled principal components: 93.55%\n",
      "Variance explained by 15 scaled principal components: 90.78%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 51, 41, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Pipeline (these values are placeholders)\n",
    "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('dim_reducer', PCA()), ('model', LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for log reg\n",
    "logreg_param_grid = [\n",
    "    # l1 without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(penalty='l1', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l1 with PCA\n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50],\n",
    "     'model': [LogisticRegression(penalty='l1', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) with PCA\n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50],\n",
    "     'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the log reg grid search\n",
    "logreg_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 823 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1021 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 11.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_em = logreg_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmp3adcsqbd',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=40,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 46.015936254980076%\n",
      "The best log reg's accuracy on the test set: 31.01851851851852%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for SVM\n",
    "svm_param_grid = [\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [SVC()], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [SVC()],\n",
    "     'model__C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the SVM grid search\n",
    "svm_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_em = svm_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmp3adcsqbd',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=30,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 100.0%\n",
      "The best SVM's accuracy on the test set: 38.425925925925924%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for KNN\n",
    "knn_param_grid = [\n",
    "    # unscaled and scaled * 10 Ks = 20 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [KNeighborsClassifier(n_jobs=-1)], 'model__n_neighbors': np.arange(3, 22, 2)},\n",
    "    \n",
    "    # unscaled and scaled * 5 PCAs * 10 Ks = 100 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "     'model__n_neighbors': np.arange(3, 22, 2)}\n",
    "]\n",
    "\n",
    "# Instantiate the grid search\n",
    "knn_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmp3adcsqbd',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=7, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 50.79681274900398%\n",
      "The best KNN model's accuracy on the test set: 35.18518518518518%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for random forest (scaling is unnecessary)\n",
    "rf_param_grid = [\n",
    "    # 5 numbers of estimators * 5 max depths = 25 models\n",
    "    {'scaler': [None], 'dim_reducer': [None], 'model': [RandomForestClassifier(n_jobs=-1)], 'model__n_estimators': np.arange(100, 501, 100),\n",
    "     'model__max_depth': np.arange(5, 26, 5)},\n",
    "    \n",
    "    # 5 PCAs * 5 numbers of estimators * 5 max depths = 150 models\n",
    "    {'scaler': [None], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [RandomForestClassifier(n_jobs=-1)],\n",
    "     'model__n_estimators': np.arange(100, 501, 100), 'model__max_depth': np.arange(5, 26, 5)}\n",
    "]\n",
    "\n",
    "# Instantiate the rf grid search\n",
    "rf_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmp3adcsqbd',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=15,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=500, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 33.7962962962963%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only female recordings\n",
    "female_df = df[df['Gender'] == 'female'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xf = female_df.iloc[:, :-2]\n",
    "ef = female_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xf_train, Xf_test, ef_train, ef_test = train_test_split(Xf, ef, test_size=0.3, stratify=ef, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 130)\n",
      "(216, 130)\n",
      "(504,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xf_train.shape)\n",
    "print(Xf_test.shape)\n",
    "print(ef_train.shape)\n",
    "print(ef_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 79.96031746031747%\n",
      "Model accuracy on test set: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_ef = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_ef.fit(Xf_train, ef_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_ef.score(Xf_train, ef_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_ef.score(Xf_test, ef_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                    5               4                    1   \n",
       "Actual calm                     0              10                    3   \n",
       "Actual disgusted                2               8                    6   \n",
       "Actual fearful                  1               5                    2   \n",
       "Actual happy                    2               0                    4   \n",
       "Actual neutral                  0               4                    1   \n",
       "Actual sad                      2               6                    1   \n",
       "Actual surprised                5               3                    1   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      5                3                  2   \n",
       "Actual calm                       3                2                  4   \n",
       "Actual disgusted                  5                2                  1   \n",
       "Actual fearful                    9                4                  1   \n",
       "Actual happy                      1                9                  2   \n",
       "Actual neutral                    1                1                  1   \n",
       "Actual sad                        2                6                  2   \n",
       "Actual surprised                  4                3                  1   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  2                    7  \n",
       "Actual calm                   3                    4  \n",
       "Actual disgusted              0                    5  \n",
       "Actual fearful                2                    5  \n",
       "Actual happy                  6                    5  \n",
       "Actual neutral                4                    2  \n",
       "Actual sad                    6                    4  \n",
       "Actual surprised              3                    8  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_ef make predictions based on the test set features\n",
    "ef_pred = initial_logreg_ef.predict(Xf_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "ef_confusion_df = pd.DataFrame(confusion_matrix(ef_test, ef_pred))\n",
    "ef_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "ef_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "ef_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.17      0.22        29\n",
      "        calm       0.25      0.34      0.29        29\n",
      "   disgusted       0.32      0.21      0.25        29\n",
      "     fearful       0.30      0.31      0.31        29\n",
      "       happy       0.30      0.31      0.31        29\n",
      "     neutral       0.07      0.07      0.07        14\n",
      "         sad       0.23      0.21      0.22        29\n",
      "   surprised       0.20      0.29      0.24        28\n",
      "\n",
      "    accuracy                           0.25       216\n",
      "   macro avg       0.25      0.24      0.24       216\n",
      "weighted avg       0.26      0.25      0.25       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(ef_test, ef_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train\n",
    "pca = PCA().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_pca = pca.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_pca = pca.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xf_train\n",
    "scaler = StandardScaler().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_scaled = scaler.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_scaled = scaler.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train_scaled\n",
    "pca_scaled = PCA().fit(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_train_scaled\n",
    "Xf_train_scaled_pca = pca_scaled.transform(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_test_scaled\n",
    "Xf_test_scaled_pca = pca_scaled.transform(Xf_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFgCAYAAABNIolGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZhkdXn28e/tIKKAEmFcgGF11ABR1AEk8XVBTVAUTETBuOECcSFuccFoFDGLxpjEvKKIiJpERQSUEVFcwPUVZHFjER0RZQQUkU1BcOB5/zinsbrppapnqud01fdzXXV1naVOPXW6puuep37nnFQVkiRJkiRJXXan9V2AJEmSJEnSXGxgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSGpU5JcmuRxC/1YSZK0OCWpJPdb6MdKWng2MKR1oP2P801JfpPkF0k+mGSTnuV/keSrSW5IclWSryTZd8o2Ht1+iL52Aev+UJJ/nDJvu7aODRaqjoXQvtZb2t/RxO2AdbBdg48kaUEt4tyxWZJjk1zZ1vbDJK9bqOcfVJIvJ/ndlOyw51pucyRzlrRQbGBI686Tq2oT4KHAbsAbAZLsD3wC+G9ga+DewJuAJ095/HOBX7c/NRz/WlWb9Nw+vr4LSrJkfdcgSVqUFmPu+A9gE+CPgXsA+wI/XsDnn49Dp2SHb67PYtLw/3AaW775pXWsqn4OfBbYJUmAfwfeWlXHVNV1VXVbVX2lqg6eeEySuwH7Ay8FlidZMdtzJDk4yaokv06yMsmWPcsqyYuS/CjJNUmObOuYl/Zbnlcn+V6S65J8PMlG7bItkpyS5Nq2lq9NfKgmWZbkpPabn6uTvLudv2OS09t5v0rykSSbzfDcd0pyWJIft+sfn+SePcufneSn7bI3rMVr3DLJiW2tP0nysp5luyf5Zvsar0jy7iQbtsu+2q723YkRHUkOSvL1Kdu/fZRGOxLkvUlOTfJb4DFJ7pLk35L8rP0m7agkd51rH0uStMhyx27AR6vqmrauH1TVCT3b2jnJF9rn+UWSv2/nz/hZPE2tM36mtstf027j8iTPn2P3zrZPHthT68VJnt6zbJ8k305yfZLLkhze89CJ7HBtmx32THJ4kv/tefykURppRoL8U5JvADcCOyS5R5IPtK/l50n+Me2XIknul2bUzXVt1lrvX9hI64ohWFrHkiwDngh8G3gAsAw4YdYHwVOB39B8Y3Ia8JxZtr8X8C/A04H7Aj8Fjpuy2pNoQsKD2/X+YtDXMcXTgb2B7YEHAQe18/8OWA0spfmG5++Baj9AT2lr2w7YqqfGtPVvSfMNzDLg8Bme92XAU4BHtetfAxwJkGQn4L3As9tlm9N80zSQthnwaeC7bZ2PBV6RZGKf3Qq8EtgC2LNd/hKAqnpku86DBxzR8dfAPwGbAl8H3g7cH9gVuF9bx5vadafdx4O+TknSaFpkueNM4J+SPC/J8inPsynwReBzNJ/r9wO+1C6e8bN4GjN+pibZG3g18HhgOTDfc25tDHwB+ChwL+AZwHuS7Nyu8luafboZsA/w4iRPaZdNZIfNBhzR8WzgEJrs8FPgw8Ca9jU+BPhz4IXtum8FPg/8EU02+r/zeJlSJ9nAkNadTyW5luY/pF8B/pnmP9UAV8zx2OcCH6+qW2k+DJ+R5M4zrPtM4NiqOq+qbgZeD+yZZLuedd5WVddW1c+AM2g+xNfGf1XV5VX1a5r/7E9s7/c0YWbbqvp9VX2tqgrYnSZ8vKaqfltVv6uqrwNU1aqq+kJV3VxVV9F8U/SoGZ73b4A3VNXq9rUeDuzffiOxP3BKVX21XfYPwG1zvI5Xt9/eXJvkV+283YClVXVEVd1SVZcA7wcObOs9t6rOrKo1VXUp8L5Z6u3XyVX1jaq6DbgZOBh4ZVX9uqpuoHnvHNiuO9M+liSNt8WYO/4W+AhwKHBhO6rjCe2yJwFXVtU729xwQ1WdBf1/FrcjP2b7TH068MGqOr+qfsvMX6D0+q+e7HBeT62XVtUH25rOA06kySZU1Zer6vvtKJPvAR+brt4BfaiqLqiqNcA9gScAr2hz1i9pDs/pzQ7bAlv2ZjBpFNjAkNadp1TVZlW1bVW9pKpuAq5ul913pge135w8huYDHeBkYCOajv10tqTpvANQVb9pn2ernnWu7Ll/I83xptNZA0wNLHemaQT0NgNm2t47gFXA55NckuSwdv4y4Kfth+wkSe6V5Lh2uOP1wP/SfKMynW2BT04EB+Aimm9h7k2zHy6bWLENIldPu5U/+Lf2d7RZVU0857bAlj3h5FqaUQ73buu9f3sIx5Vtvf88S739uqzn/lLgbsC5Pc//uXY+zLyPJUnjbdHljqq6qar+uaoeRtNsOR74RJrDQ5cxw/kwBvgsnuszdVJ26H1ds3hZT3Z4aDtvW2CPKdnhmcB92nr3SHJGmkNTrwNeNEO9g+ite1uavHZFz/O/j2Y0CMBraUa8fivJBWtzqIzUNTYwpOG6mOYD56mzrPNsmn+Ln05yJXAJTZCYaTjn5TQfXMDtwxg3B34+j/p+RnOIR6/tgcva0QGzar8d+buq2oHm5GCvSvJYmte8TaY/w/a/0BwC8aCqujvwLJoP2elcBjyhJzhsVlUbtcf7XkETdoDbj+fdfIbtzOYy4CdTnmPTqnpiu/y9wA+A5W29fz9LvdAMG71bT133mWad3hEUvwJuAnbuef57VHNittn2sSRJU3U9d9yuqiYaERvTZg9gxxlW7/ezeNbPVKZkB2CbeZZ/GfCVKdlhk6p6cbv8o8BKYFlV3QM4qqfe6UZRTsoOtI2QKXofdxnNCM4tep7/7lW1M0BVXVlVB1fVljSjWd8Tr5imEWEDQxqidqj/q4B/aI/3vHuaE1M+IsnR7WrPAd5CM9xy4vZUYJ8k0/2H/KPA85LsmuQuNB/+Z7VDKgd1Yvs8f55kSZqTcr2ROx7bOq0kT2pPFBXgeprREbcC36IJCW9LsnGSjZL8WfuwTWmOu702yVbAa2Z5iqNojpXdtn2+pUn2a5edADyp3ZcbAkcwv79p3wKuT/K6JHdt98MuSXbrqfd64DdJHgi8eMrjfwHs0DP9XWDn9vezEXMMT20bRe8H/iPJvdrXudXEOThm2ceSJE3S9dyR5B+S7JZkw/Yz8uXAtTSNl1OA+yR5RZoTcW6aZI/2oXN9Fk+8/lk/U2lGfByUZKf2i483D/oaWqcA909zMvE7t7fdkvxxT72/rqrfJdmd5txXE66iGeXamx2+AzwyyTZJ7kFzmM6MquoKmnNcvLPnd7xjkke1r/lpSSbOC3YNTfPD7KCRYANDGrJqzq59APB8mm8xfgH8I3BykofTjIA4su2WT9xW0hw28IxptvclmvM9nEjTJNiRPxzzOGhtF7TP8S80l1L7JnAWTbDpx3KaE279pn3se9rjPm+lGS1wP5pRHqtp9gHtth8KXAd8Bjhplu2/i+YbjM8nuYHm5F979NT+UppgdQXNB/TqPuu+XU+tuwI/ofn25hiay7tBc7KvvwZuoAlFU0/UeTjw4XYI59Or6oc0zZQvAj+iOTZ5Lq+j+X2f2Q6N/SLNidhghn086OuUJI2HLucOmv9If5Dms/ZympNp7lNVv2nPV/F4ms/kK2k+Qx/TPm6uz+JeM36mVtVngf8ETm/XOX1eL6Kp9c9p9sPlbb1vB+7SrvIS4Ig2u7yJpnEy8dgbaU7k/Y02Ozy8qr7QvqbvAefSNEjm8hxgQ+BCmgx0An84dGg34Kwkv6HJUS+vqp/M57VKXZPyXHCSJEmSJKnjHIEhSZIkSZI6b6gNjCR7J7k4zSWSpj1zfpKnJ7mwPUPuR4dZjyRJWrzMFZIkjbehHUKSZAnwQ5pj2VYDZwPPqKoLe9ZZTnNM2F5VdU2Se7XXMZYkSbqduUKSJA1zBMbuwKqquqSqbqG5qsF+U9Y5mOYkQtcAGDIkSdIMzBWSJI25DYa47a1orlE8YTXt1QN63B8gyTeAJcDhVfW5qRtKcghwCMDGG2/8sAc+8IHrvNjv//y62+//yVb3mGVNSZLU69xzz/1VVS0d8tOss1zRrmO2kCSpo2bKFsNsYGSaeVOPV9mA5hKBjwa2Br6WZJequnbSg6qOBo4GWLFiRZ1zzjnrvNjtDvvM7ffPeds+63z7kiSNqiQ/XYinmWbevHIFmC0kSeqymbLFMA8hWQ0s65nemuY6yVPXObmqft9em/himuAhSZLUy1whSdKYG2YD42xgeZLtk2wIHAisnLLOp4DHACTZgmbo5yVDrEmSJC1O5gpJksbc0BoYVbUGOBQ4DbgIOL6qLkhyRJJ929VOA65OciFwBvCaqrp6WDVJkqTFyVwhSZKGeQ4MqupU4NQp897Uc7+AV7U3SZKkGZkrJEkab8M8hESSJEmSJGmdsIEhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp84bawEiyd5KLk6xKctg0yw9KclWS77S3Fw6zHkmStHiZKyRJGm8bDGvDSZYARwKPB1YDZydZWVUXTln141V16LDqkCRJi5+5QpIkDXMExu7Aqqq6pKpuAY4D9hvi80mSpNFlrpAkacwNs4GxFXBZz/Tqdt5UT03yvSQnJFk23YaSHJLknCTnXHXVVcOoVZIkdds6yxVgtpAkaTEaZgMj08yrKdOfBrarqgcBXwQ+PN2GquroqlpRVSuWLl26jsuUJEmLwDrLFWC2kCRpMRpmA2M10PvNx9bA5b0rVNXVVXVzO/l+4GFDrEeSJC1e5gpJksbcMBsYZwPLk2yfZEPgQGBl7wpJ7tszuS9w0RDrkSRJi5e5QpKkMTe0q5BU1ZokhwKnAUuAY6vqgiRHAOdU1UrgZUn2BdYAvwYOGlY9kiRp8TJXSJKkoTUwAKrqVODUKfPe1HP/9cDrh1mDJEkaDeYKSZLG2zAPIZEkSZIkSVonbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOm+DuVZIcmfgxcAj21lfAY6qqt8PszBJkjSazBaSJGk+5mxgAO8F7gy8p51+djvvhcMqSpIkjTSzhSRJGlg/DYzdqurBPdOnJ/nusAqSJEkjz2whSZIG1s85MG5NsuPERJIdgFuHV5IkSRpxZgtJkjSwfkZgvAY4I8klQIBtgecNtSpJkjTKzBaSJGlgczYwqupLSZYDD6AJGT+oqpuHXpkkSRpJZgtJkjQfMzYwkuxVVacn+aspi3ZMQlWdNOTaJEnSCDFbSJKktTHbCIxHAacDT55mWQGGDEmSNAizhSRJmrcZGxhV9eb27hFV9ZPeZUm272fjSfYG3gUsAY6pqrfNsN7+wCdozkp+Tj/bliRJi4vZQpIkrY1+rkJy4jTzTpjrQUmWAEcCTwB2Ap6RZKdp1tsUeBlwVh+1SJKkxc9sIUmSBjbbOTAeCOwM3GPKsap3BzbqY9u7A6uq6pJ2e8cB+wEXTlnvrcC/Aq8eoG5JkrTImC0kSdLamO0cGA8AngRsxuRjVW8ADu5j21sBl/VMrwb26F0hyUOAZVV1ShJDhiRJo81sIUmS5m22c2CcDJycZM+q+uY8tp3pNnv7wuROwH8AB825oeQQ4BCAbbbZZh6lSJKk9c1sIUmS1sZsIzAmfDvJS2mGfN4+vLOqnj/H41YDy3qmtwYu75neFNgF+HISgPsAK5PsO/VkW1V1NHA0wIoVKwpJkrSYmS0kSdLA+jmJ5//QBIC/AL5CExZu6ONxZwPLk2yfZEPgQGDlxMKquq6qtqiq7apqO+BM4A4BQ5IkjRyzhSRJGlg/DYz7VdU/AL+tqg8D+wB/MteDqmoNcChwGnARcHxVXZDkiCT7rk3RkiRpUTNbSJKkgfVzCMnv25/XJtkFuBLYrp+NV9WpwKlT5r1phnUf3c82JUnSome2kCRJA+ungXF0kj8C3kgzTHMTYNqgIEmS1AezhSRJGticDYyqOqa9+1Vgh+GWI0mSRp3ZQpIkzces58BIsiTJFj3TGyY5OMlFwy9NkiSNGrOFJEmarxkbGEkOBH4NfC/JV5I8BrgEeCLwzAWqT5IkjQizhSRJWhuzHULyRuBhVbUqyUOBbwIHVtUnF6Y0SZI0YswWkiRp3mY7hOSWqloFUFXnAT8xYEiSpLVgtpAkSfM22wiMeyV5Vc/0Jr3TVfXvwytLkiSNILOFJEmat9kaGO8HNp1lWpIkaRBmC0mSNG8zNjCq6i0LWYgkSRptZgtJkrQ2Zr2MqiRJkiRJUhfYwJAkSZIkSZ1nA0OSJEmSJHXenA2MJPdO8oEkn22nd0ryguGXJkmSRpHZQpIkzUc/IzA+BJwGbNlO/xB4xbAKkiRJI+9DmC0kSdKA+mlgbFFVxwO3AVTVGuDWoVYlSZJGmdlCkiQNrJ8Gxm+TbA4UQJKHA9cNtSpJkjTKzBaSJGlgG/SxzquAlcCOSb4BLAX2H2pVkiRplJktJEnSwOZsYFTVeUkeBTwACHBxVf1+6JVJkqSRZLaQJEnz0c9VSF4KbFJVF1TV+cAmSV4y/NIkSdIoMltIkqT56OccGAdX1bUTE1V1DXDw8EqSJEkjzmwhSZIG1k8D405JMjGRZAmw4fBKkiRJI85sIUmSBtbPSTxPA45PchTN2cJfBHxuqFVJkqRRZraQJEkD66eB8Trgb4AX05xo6/PAMcMsSpIkjTSzhSRJGlg/VyG5DXhve5MkSVorZgtJkjQfczYwkvwZcDiwbbt+gKqqHYZbmiRJGkVmC0mSNB/9HELyAeCVwLnArcMtR5IkjQGzhSRJGlg/DYzrquqzQ69EkiSNC7OFJEkaWD8NjDOSvAM4Cbh5YmZVnTe0qiRJ0igzW0iSpIH108DYo/25omdeAXut+3IkSdIYMFtIkqSB9XMVkscsRCGSJGk8mC0kSdJ89DMCgyT7ADsDG03Mq6ojhlWUJEkabWYLSZI0qDvNtUKSo4ADgL+luczZ02gueyZJkjQws4UkSZqPORsYwJ9W1XOAa6rqLcCewLLhliVJkkaY2UKSJA2snwbGTe3PG5NsCfwe2H54JUmSpBFntpAkSQPr5xwYpyTZDHgHcB7NWcKPGWpVkiRplJktJEnSwPq5Cslb27snJjkF2KiqrhtuWZIkaVSZLSRJ0nzM2MBIsldVnZ7kr6ZZRlWdNNzSJEnSKDFbSJKktTHbCIxHAacDT55mWQGGDEmSNAizhSRJmrcZGxhV9eYkdwI+W1XHL2BNkiRpBJktJEnS2pj1KiRVdRtw6ALVIkmSRpzZQpIkzVc/l1H9QpJXJ1mW5J4Tt342nmTvJBcnWZXksGmWvyjJ95N8J8nXk+w08CuQJEmLjdlCkiQNrJ/LqD6//fnSnnkF7DDbg5IsAY4EHg+sBs5OsrKqLuxZ7aNVdVS7/r7AvwN791m7JElanMwWkiRpYP1cRnX7eW57d2BVVV0CkOQ4YD/g9pBRVdf3rL8xTXiRJEkjzGwhSZLmo58RGCTZBdgJ2GhiXlX99xwP2wq4rGd6NbDHNNt+KfAqYENgrxme/xDgEIBtttmmn5IlSVKHmS0kSdKg5jwHRpI3A/+3vT0G+Fdg3z62nWnm3eFbkKo6sqp2BF4HvHG6DVXV0VW1oqpWLF26tI+nliRJXWW2kCRJ89HPSTz3Bx4LXFlVzwMeDNylj8etBpb1TG8NXD7L+scBT+lju5IkaXEzW0iSpIH108C4qb3k2Zokdwd+yRwn2WqdDSxPsn2SDYEDgZW9KyRZ3jO5D/Cj/sqWJEmLmNlCkiQNrJ9zYJyTZDPg/cC5wG+Ab831oKpak+RQ4DRgCXBsVV2Q5AjgnKpaCRya5HHA74FrgOfO83VIkqTFw2whSZIG1s9VSF7S3j0qyeeAu1fV9/rZeFWdCpw6Zd6beu6/fIBaJUnSCDBbSJKk+ZjxEJIkFyZ5Q5IdJ+ZV1aX9BgxJkqReZgtJkrQ2ZjsHxjOATYDPJzkrySuSbLlAdUmSpNFjtpAkSfM2YwOjqr5bVa9vL0P2cmBb4Mwkpyc5eMEqlCRJI8FsIUmS1kY/VyGhqs6sqlcCzwH+CHj3UKuSJEkjzWwhSZIGNedJPJPsRjPk86nApcDRwCeGW5YkSRpVZgtJkjQfMzYwkvwzcADNJciOA/6sqlYvVGGSJGm0mC0kSdLamG0Exs3AE6rqhwtVjCRJGmlmC0mSNG8zNjCq6i0LWYgkSRptZgtJkrQ2+jqJpyRJkiRJ0vpkA0OSJEmSJHXebCfxfOhsD6yq89Z9OZIkaVSZLSRJ0tqY7SSe72x/bgSsAL4LBHgQcBbwiOGWJkmSRozZQpIkzduMh5BU1WOq6jHAT4GHVtWKqnoY8BBg1UIVKEmSRoPZQpIkrY1+zoHxwKr6/sREVZ0P7Dq8kiRJ0ogzW0iSpIHNdgjJhIuSHAP8L1DAs4CLhlqVJEkaZWYLSZI0sH4aGM8DXgy8vJ3+KvDeoVUkSZJGndlCkiQNbM4GRlX9LslRwKlVdfEC1CRJkkaY2UKSJM3HnOfASLIv8B3gc+30rklWDrswSZI0mswWkiRpPvo5ieebgd2BawGq6jvAdkOsSZIkjTazhSRJGlg/DYw1VXXd0CuRJEnjwmwhSZIG1s9JPM9P8tfAkiTLgZcB/2+4ZUmSpBFmtpAkSQPrZwTG3wI7AzcDHwOuB14xzKIkSdJIM1tIkqSB9XMVkhuBN7Q3SZKktWK2kCRJ8zFnAyPJ/YFX05xc6/b1q2qv4ZUlSZJGldlCkiTNRz/nwPgEcBRwDHDrcMuRJEljwGwhSZIG1k8DY01VvXfolUiSpHFhtpAkSQPr5ySen07ykiT3TXLPidvQK5MkSaPKbCFJkgbWzwiM57Y/X9Mzr4Ad1n05kiRpDJgtJEnSwPq5Csn2C1GIJEkaD2YLSZI0HzM2MJLsVVWnJ/mr6ZZX1UnDK0uSJI0as4UkSVobs43AeBRwOvDkaZYVYMiQJEmDMFtIkqR5m7GBUVVvbn8+b+HKkSRJo8psIUmS1kY/J/EkyT7AzsBGE/Oq6ohhFSVJkkab2UKSJA1qzsuoJjkKOAD4WyDA04Bth1yXJEkaUWYLSZI0H3M2MIA/rarnANdU1VuAPYFlwy1LkiSNMLOFJEkaWD8NjJvanzcm2RL4PeDlzyRJ0nyZLSRJ0sD6OQfGKUk2A94BnEdzlvBjhlqVJEkaZWYLSZI0sDkbGFX11vbuiUlOATaqquuGW5YkSRpVZgtJkjQfMzYwkvzVLMuoKq/VLkmS+ma2kCRJa2O2ERhPnmVZAXOGjCR7A+8ClgDHVNXbpix/FfBCYA1wFfD8qvrpXNuVJEmL0lplC3OFJEnjbcYGRlU9b202nGQJcCTweGA1cHaSlVV1Yc9q3wZWVNWNSV4M/CvNZdUkSdKIWZtsYa6QJElzXoUkyeZJ/ivJeUnOTfKuJJv3se3dgVVVdUlV3QIcB+zXu0JVnVFVN7aTZwJbD/oCJEnS4jLPbGGukCRpzPVzGdXjaIZhPhXYv73/8T4etxVwWc/06nbeTF4AfLaP7UqSpMVtPtnCXCFJ0pjr5zKq9+w5WzjAPyZ5Sh+PyzTzatoVk2cBK4BHzbD8EOAQgG222aaPp5YkSR02n2yxznJFu47ZQpKkRaafERhnJDkwyZ3a29OBz/TxuNXAsp7prYHLp66U5HHAG4B9q+rm6TZUVUdX1YqqWrF06dI+nlqSJHXYfLLFOssVYLaQJGkx6qeB8TfAR4Gb29txwKuS3JDk+lkedzawPMn2STYEDgRW9q6Q5CHA+2hCxi/n8wIkSdKiM59sYa6QJGnMzXkISVVtOp8NV9WaJIcCp9Fc7uzYqrogyRHAOVW1EngHsAnwiSQAP6uqfefzfJIkaXGYT7YwV0iSpDkbGEleUFUf6JleAryxqt4y12Or6lTg1Cnz3tRz/3GDlStJkha7+WYLc4UkSeOtn0NIHpvk1CT3TfInNJclm9eoDEmSJMwWkiRpHvo5hOSvkxwAfB+4EXhGVX1j6JVJkqSRZLaQJEnzMecIjCTLgZcDJwKXAs9Ocrch1yVJkkaU2UKSJM1HP4eQfBr4h6r6G5rrqf+I5kzgkiRJ82G2kCRJA5vzEBJg96q6HqCqCnhnkpVzPEaSJGkmZgtJkjSwGUdgJHktQFVdn+RpUxY/b6hVSZKkkWO2kCRJa2O2Q0gO7Ln/+inL9h5CLZIkabSZLSRJ0rzN1sDIDPenm5YkSZqL2UKSJM3bbA2MmuH+dNOSJElzMVtIkqR5m+0kng9Ocj3NNyJ3be/TTm809MokSdKoMVtIkqR5m7GBUVVLFrIQSZI02swWkiRpbcx2CF9KBV0AABAGSURBVIkkSZIkSVIn2MCQJEmSJEmdZwNDkiRJkiR1ng0MSZIkSZLUeTYwJEmSJElS59nAkCRJkiRJnWcDQ5IkSZIkdZ4NDEmSJEmS1Hk2MCRJkiRJUufZwJAkSZIkSZ1nA0OSJEmSJHWeDQxJkiRJktR5NjAkSZIkSVLn2cCQJEmSJEmdZwNDkiRJkiR1ng0MSZIkSZLUeTYwJEmSJElS59nAkCRJkiRJnWcDQ5IkSZIkdZ4NDEmSJEmS1Hk2MCRJkiRJUufZwJAkSZIkSZ1nA0OSJEmSJHWeDQxJkiRJktR5NjAkSZIkSVLn2cCQJEmSJEmdZwNDkiRJkiR1ng0MSZIkSZLUeTYwJEmSJElS5w21gZFk7yQXJ1mV5LBplj8yyXlJ1iTZf5i1SJKkxc1cIUnSeBtaAyPJEuBI4AnATsAzkuw0ZbWfAQcBHx1WHZIkafEzV0iSpA2GuO3dgVVVdQlAkuOA/YALJ1aoqkvbZbcNsQ5JkrT4mSskSRpzwzyEZCvgsp7p1e28gSU5JMk5Sc656qqr1klxkiRpUVlnuQLMFpIkLUbDbGBkmnk1nw1V1dFVtaKqVixdunQty5IkSYvQOssVYLaQJGkxGmYDYzWwrGd6a+DyIT6fJEkaXeYKSZLG3DAbGGcDy5Nsn2RD4EBg5RCfT5IkjS5zhSRJY25oDYyqWgMcCpwGXAQcX1UXJDkiyb4ASXZLshp4GvC+JBcMqx5JkrR4mSskSdIwr0JCVZ0KnDpl3pt67p9NMwRUkiRpVuYKSZLG2zAPIZEkSZIkSVonbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfM2WN8FSJIkjbrtDvvM7fcvfds+67ESSZIWL0dgzGC7wz4zKWxIkiRJkqT1xwaGJEmSJEnqPA8h6YPDPiVJkiRJWr8cgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEkLzJOFS5I0OBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOs8GhiRJkiRJ6jwbGJIkSZIkqfNsYEiSJEmSpM6zgSFJkiRJkjrPBoYkSZIkSeo8GxiSJEmSJKnzbGBIkiRJkqTOs4EhSZIkSZI6zwaGJEmSJEnqPBsYkiRJkiSp82xgSJIkSZKkzrOBIUmSJEmSOm+D9V3AYrPdYZ+5/f6lb9tnPVYiSZJGgdlCkqT+OAJDkiRJkiR1ng0MSZIkSZLUeR5CspYc9ilJktYVc4UkSTOzgbEOGTokSZIkSRoOGxiSJEkd5ZcjkiT9gQ2MIZoIHZe+bR8DiCRJWitTs0RvzpAkaRzYwFgPbGZIkqR1yWwhSRoHNjA6oDd09DKASJKk+ZhpFGgvR3FIkhaboTYwkuwNvAtYAhxTVW+bsvwuwH8DDwOuBg6oqkuHWdNiM9thKIOGk4lpSZIWK7PF8Mw3Z0iStFCG1sBIsgQ4Eng8sBo4O8nKqrqwZ7UXANdU1f2SHAi8HThgWDXJcCJJWrzMFt3U7wgPv2yRJK2tYY7A2B1YVVWXACQ5DtgP6A0Z+wGHt/dPAN6dJFVVQ6xL87Cuw0m/25jP9tfVaJVhv05J0sDMFmNgIT/DF3vOME9IGjcZ1ud5kv2Bvavqhe30s4E9qurQnnXOb9dZ3U7/uF3nV1O2dQhwSDv5AODidVjqFsCv5lxrfLg/7sh9Mpn7YzL3x2Tuj8nGZX9sW1VLh/0kZotFy/0xmftjMvfHHblPJnN/TDYu+2PabDHMERiZZt7Ubkk/61BVRwNHr4uipkpyTlWtGMa2FyP3xx25TyZzf0zm/pjM/TGZ+2OdM1ssQu6Pydwfk7k/7sh9Mpn7Y7Jx3x93GuK2VwPLeqa3Bi6faZ0kGwD3AH49xJokSdLiZbaQJGmMDbOBcTawPMn2STYEDgRWTllnJfDc9v7+wOkeoypJkmZgtpAkaYwN7RCSqlqT5FDgNJpLnR1bVRckOQI4p6pWAh8A/ifJKppvRw4cVj2zGMrw0UXM/XFH7pPJ3B+TuT8mc39M5v5Yh8wWi5b7YzL3x2Tujztyn0zm/phsrPfH0E7iKUmSJEmStK4M8xASSZIkSZKkdcIGhiRJkiRJ6ryxbmAk2TvJxUlWJTlsfdez0JIsS3JGkouSXJDk5e38eyb5QpIftT//aH3XupCSLEny7SSntNPbJzmr3R8fb08cNxaSbJbkhCQ/aN8ne47z+yPJK9t/K+cn+ViSjcbt/ZHk2CS/THJ+z7xp3xNp/Ff7N/Z7SR66/iofjhn2xzvafzPfS/LJJJv1LHt9uz8uTvIX66dqDYu5wlwxHXPFZGaLycY9W5gr7shsMbuxbWAkWQIcCTwB2Al4RpKd1m9VC24N8HdV9cfAw4GXtvvgMOBLVbUc+FI7PU5eDlzUM/124D/a/XEN8IL1UtX68S7gc1X1QODBNPtlLN8fSbYCXgasqKpdaE4geCDj9/74ELD3lHkzvSeeACxvb4cA712gGhfSh7jj/vgCsEtVPQj4IfB6gPbv64HAzu1j3tN+FmkEmCsAc8VMzBWTmS1aZgvAXDGdD2G2mNHYNjCA3YFVVXVJVd0CHAfst55rWlBVdUVVndfev4HmA2Qrmv3w4Xa1DwNPWT8VLrwkWwP7AMe00wH2Ak5oVxmb/ZHk7sAjac7oT1XdUlXXMsbvD5orN901yQbA3YArGLP3R1V9lebKDr1mek/sB/x3Nc4ENkty34WpdGFMtz+q6vNVtaadPBPYur2/H3BcVd1cVT8BVtF8Fmk0mCvMFXdgrpjMbDGtsc4W5oo7MlvMbpwbGFsBl/VMr27njaUk2wEPAc4C7l1VV0ATRoB7rb/KFtx/Aq8FbmunNweu7fmDMU7vkx2Aq4APtkNfj0myMWP6/qiqnwP/BvyMJlxcB5zL+L4/es30nvDvLDwf+Gx73/0x2vz99jBX3M5cMZnZoofZYkbmitmNdbYY5wZGppk3lteUTbIJcCLwiqq6fn3Xs74keRLwy6o6t3f2NKuOy/tkA+ChwHur6iHAbxmTIZ3TaY+/3A/YHtgS2JhmKONU4/L+6Mc4//shyRtohtR/ZGLWNKuNzf4YA/5+W+aKhrliWmaLHmaLgY37vx+zBePdwFgNLOuZ3hq4fD3Vst4kuTNNyPhIVZ3Uzv7FxHCs9ucv11d9C+zPgH2TXEoz9Hcvmm9ONmuH9cF4vU9WA6ur6qx2+gSa0DGu74/HAT+pqquq6vfAScCfMr7vj14zvSfG9u9skucCTwKeWVUTQWJs98eY8PeLuWIKc8UdmS0mM1tMz1wxDbNFY5wbGGcDy9uz/G5Ic/KTleu5pgXVHof5AeCiqvr3nkUrgee2958LnLzQta0PVfX6qtq6qrajeT+cXlXPBM4A9m9XG6f9cSVwWZIHtLMeC1zImL4/aIZ3PjzJ3dp/OxP7YyzfH1PM9J5YCTynPWv4w4HrJoaEjrIkewOvA/atqht7Fq0EDkxylyTb05yE7Fvro0YNhbnCXDGJueKOzBZ3YLaYnrliCrPFH+QPzZvxk+SJNJ3wJcCxVfVP67mkBZXkEcDXgO/zh2Mz/57meNXjgW1o/rA+raqmnlxnpCV5NPDqqnpSkh1ovjm5J/Bt4FlVdfP6rG+hJNmV5sRjGwKXAM+jaXyO5fsjyVuAA2iG7n0beCHNcYZj8/5I8jHg0cAWwC+ANwOfYpr3RBvG3k1zVuwbgedV1Tnro+5hmWF/vB64C3B1u9qZVfWidv030By7uoZmeP1np25Ti5e5wlwxE3PFH5gtJhv3bGGuuCOzxezGuoEhSZIkSZIWh3E+hESSJEmSJC0SNjAkSZIkSVLn2cCQJEmSJEmdZwNDkiRJkiR1ng0MSZIkSZLUeTYwpEUmya1JvpPk/CSfSHK3GdY7Nclm89j+lklOWIv6Lk2yxTTzN0nyviQ/TnJBkq8m2WO+z9MFSXZtL5soSdKiZK7oDnOFNDcbGNLic1NV7VpVuwC3AC/qXZjGnarqiVV17aAbr6rLq2r/dVVsj2OAXwPLq2pn4CCa61svZrsCBg1J0mJmrugOc4U0BxsY0uL2NeB+SbZLclGS9wDnAcsmvrHoWfb+9huKzye5K0CS+yX5YpLvJjkvyY7t+ue3yw9KcnKSzyW5OMmbJ544yaeSnNtu85DZikyyI7AH8Maqug2gqi6pqs+0y1/VfvNzfpJXtPO2S/KDJMe08z+S5HFJvpHkR0l2b9c7PMn/JDm9nX9wOz9J3tE+9vtJDmjnPzrJl5Oc0G7/I0nSLntYkq+0r+u0JPdt5385yduTfCvJD5P8nyQbAkcAB7TfXB2wjn6nkiStL+YKc4XUbVXlzZu3RXQDftP+3AA4GXgxsB1wG/DwnvUupfkmYjtgDbBrO/944Fnt/bOAv2zvbwTcrV3//HbeQcAVwObAXYHzgRXtsnu2Pyfmb977vFNq3hf45Ayv52HA94GNgU2AC4CH9NT9JzTN1nOBY4EA+wGfah9/OPDdto4tgMuALYGnAl8AlgD3Bn4G3Bd4NHAdsHW73W8CjwDuDPw/YGm73QOAY9v7Xwbe2d5/IvDFnv3z7vX9nvDmzZs3b97mezNXmCu8eVtMtw2QtNjcNcl32vtfAz5A88H606o6c4bH/KSqJh5zLrBdkk2BrarqkwBV9TuA9kuDXl+oqqvbZSfRfCifA7wsyV+26ywDlgNXz+P1PIImhPy25zn+D7Cyrfv77fwLgC9VVSX5Pk0QmXByVd0E3JTkDGD3drsfq6pbgV8k+QqwG3A98K2qWt1u9zvttq4FdgG+0O6DJTQha8JJ7c9zpzy3JEmLmbnCXCEtGjYwpMXnpqratXdG+8H421kec3PP/VtpvlW4Q6KYQU2dTvJo4HHAnlV1Y5Iv03zTMpMLgAenOYb2tinLZqujt+7beqZvY/LfrzvUOMB2b223FeCCqtpzjsdMrC9J0igwV5grpEXDc2BIY6qqrgdWJ3kKQJK7ZPozjz8+yT3b41ufAnwDuAdwTRsyHgg8fI7n+jHNtytv6TkudHmS/YCvAk9JcrckGwN/SfMN0CD2S7JRks1phnKe3W73gCRLkiwFHgl8a5ZtXAwsTbJnW9+dk+w8x/PeAGw6YK2SJI0cc8UdmCukIbCBIY23Z9MM2fwezXGa95lmna8D/wN8Bzixqs4BPgds0D7urcBMQ0x7vbDd/qp2qOb7gcur6jzgQzQh4CzgmKr69oCv41vAZ9o63lpVlwOfBL5Hcxzr6cBrq+rKmTZQVbcA+wNvT/Ld9vX+6RzPewawkyfbkiQJMFfczlwhDUeqpo6QkqRGkoNoTq516PquZSZJDqc5Adm/re9aJEnSzMwVktaWIzAkSZIkSVLnOQJDkiRJkiR1niMwJEmSJElS59nAkCRJkiRJnWcDQ5IkSZIkdZ4NDEmSJEmS1Hk2MCRJkiRJUuf9f8AdMDxaa58tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 50 unscaled principal components: 99.18%\n",
      "Variance explained by 40 unscaled principal components: 98.58%\n",
      "Variance explained by 30 unscaled principal components: 97.49%\n",
      "Variance explained by 20 unscaled principal components: 95.47%\n",
      "Variance explained by 15 unscaled principal components: 93.41%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 51, 41, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 50 scaled principal components: 99.17%\n",
      "Variance explained by 40 scaled principal components: 98.55%\n",
      "Variance explained by 30 scaled principal components: 97.42%\n",
      "Variance explained by 20 scaled principal components: 95.27%\n",
      "Variance explained by 15 scaled principal components: 93.18%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 51, 41, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, I will now do a grid search for each classifier type, with five-fold cross-validation to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Pipeline (these values are placeholders)\n",
    "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('dim_reducer', PCA()), ('model', LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for log reg\n",
    "logreg_param_grid = [\n",
    "    # l1 without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(penalty='l1', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l1 with PCA\n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50],\n",
    "     'model': [LogisticRegression(penalty='l1', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) with PCA\n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50],\n",
    "     'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the log reg grid search\n",
    "logreg_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 379 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 609 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 978 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 11.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_ef = logreg_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpn3skoxna',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.01, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                    random_state=None, solver='lbfgs',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 40.07936507936508%\n",
      "The best log reg's accuracy on the test set: 37.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for SVM\n",
    "svm_param_grid = [\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [SVC()], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # unscaled and scaled * 5 PCAs * 9 regularization strengths = 90 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [SVC()],\n",
    "     'model__C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the SVM grid search\n",
    "svm_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   10.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_ef = svm_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpn3skoxna',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=30,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 100.0%\n",
      "The best SVM's accuracy on the test set: 41.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for KNN\n",
    "knn_param_grid = [\n",
    "    # unscaled and scaled * 10 Ks = 20 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [KNeighborsClassifier(n_jobs=-1)], 'model__n_neighbors': np.arange(3, 22, 2)},\n",
    "    \n",
    "    # unscaled and scaled * 5 PCAs * 10 Ks = 100 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "     'model__n_neighbors': np.arange(3, 22, 2)}\n",
    "]\n",
    "\n",
    "# Instantiate the grid search\n",
    "knn_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   21.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpn3skoxna',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=7, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 50.79681274900398%\n",
      "The best KNN model's accuracy on the test set: 35.18518518518518%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for random forest (scaling is unnecessary)\n",
    "rf_param_grid = [\n",
    "    # 5 numbers of estimators * 5 max depths = 25 models\n",
    "    {'scaler': [None], 'dim_reducer': [None], 'model': [RandomForestClassifier(n_jobs=-1)], 'model__n_estimators': np.arange(100, 501, 100),\n",
    "     'model__max_depth': np.arange(5, 26, 5)},\n",
    "    \n",
    "    # 5 PCAs * 5 numbers of estimators * 5 max depths = 150 models\n",
    "    {'scaler': [None], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30, 40, 50], 'model': [RandomForestClassifier(n_jobs=-1)],\n",
    "     'model__n_estimators': np.arange(100, 501, 100), 'model__max_depth': np.arange(5, 26, 5)}\n",
    "]\n",
    "\n",
    "# Instantiate the rf grid search\n",
    "rf_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpn3skoxna',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=15,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=400, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 37.96296296296296%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
