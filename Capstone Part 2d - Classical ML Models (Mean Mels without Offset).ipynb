{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Part 2d - Classical ML Models (Mean Mels without Offset)\n",
    "___\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.533443e-10</td>\n",
       "      <td>4.470215e-11</td>\n",
       "      <td>8.070570e-11</td>\n",
       "      <td>2.146172e-10</td>\n",
       "      <td>4.451442e-10</td>\n",
       "      <td>4.280263e-10</td>\n",
       "      <td>2.788707e-10</td>\n",
       "      <td>1.879692e-09</td>\n",
       "      <td>1.174269e-09</td>\n",
       "      <td>4.461908e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.662752e-08</td>\n",
       "      <td>8.307025e-08</td>\n",
       "      <td>9.287401e-08</td>\n",
       "      <td>3.056497e-08</td>\n",
       "      <td>4.678518e-09</td>\n",
       "      <td>5.241251e-09</td>\n",
       "      <td>6.313334e-09</td>\n",
       "      <td>7.005036e-09</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.188707e-09</td>\n",
       "      <td>3.779748e-10</td>\n",
       "      <td>2.234186e-10</td>\n",
       "      <td>6.680412e-10</td>\n",
       "      <td>6.218913e-09</td>\n",
       "      <td>1.137445e-08</td>\n",
       "      <td>2.683028e-09</td>\n",
       "      <td>5.531596e-09</td>\n",
       "      <td>8.906017e-09</td>\n",
       "      <td>6.461679e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217372e-08</td>\n",
       "      <td>3.826104e-09</td>\n",
       "      <td>1.010611e-09</td>\n",
       "      <td>7.145892e-10</td>\n",
       "      <td>3.149462e-10</td>\n",
       "      <td>2.505838e-10</td>\n",
       "      <td>1.273010e-10</td>\n",
       "      <td>1.725840e-10</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.123937e-08</td>\n",
       "      <td>8.660994e-08</td>\n",
       "      <td>1.589899e-07</td>\n",
       "      <td>6.396412e-08</td>\n",
       "      <td>4.406861e-08</td>\n",
       "      <td>6.402577e-08</td>\n",
       "      <td>5.034104e-08</td>\n",
       "      <td>7.215107e-08</td>\n",
       "      <td>2.666949e-08</td>\n",
       "      <td>1.086904e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.322439e-09</td>\n",
       "      <td>1.381340e-09</td>\n",
       "      <td>1.323247e-10</td>\n",
       "      <td>2.768844e-11</td>\n",
       "      <td>1.122044e-09</td>\n",
       "      <td>1.865057e-09</td>\n",
       "      <td>4.243676e-10</td>\n",
       "      <td>4.917393e-10</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.613280e-08</td>\n",
       "      <td>2.906938e-08</td>\n",
       "      <td>3.552248e-08</td>\n",
       "      <td>5.806047e-08</td>\n",
       "      <td>4.948989e-08</td>\n",
       "      <td>5.540470e-08</td>\n",
       "      <td>2.852813e-08</td>\n",
       "      <td>3.038411e-08</td>\n",
       "      <td>4.256698e-08</td>\n",
       "      <td>2.405028e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.889469e-09</td>\n",
       "      <td>1.447878e-08</td>\n",
       "      <td>4.330400e-08</td>\n",
       "      <td>7.822125e-08</td>\n",
       "      <td>3.754572e-08</td>\n",
       "      <td>1.115205e-08</td>\n",
       "      <td>9.865569e-09</td>\n",
       "      <td>2.300178e-08</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.341250e-09</td>\n",
       "      <td>2.156079e-08</td>\n",
       "      <td>3.660990e-08</td>\n",
       "      <td>8.600722e-09</td>\n",
       "      <td>5.131207e-09</td>\n",
       "      <td>4.675287e-09</td>\n",
       "      <td>2.080450e-09</td>\n",
       "      <td>2.264334e-09</td>\n",
       "      <td>1.884883e-09</td>\n",
       "      <td>2.813915e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316695e-07</td>\n",
       "      <td>8.649530e-08</td>\n",
       "      <td>1.058607e-07</td>\n",
       "      <td>8.464285e-08</td>\n",
       "      <td>6.483439e-08</td>\n",
       "      <td>5.629305e-08</td>\n",
       "      <td>3.093712e-08</td>\n",
       "      <td>4.056278e-08</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  1.533443e-10  4.470215e-11  8.070570e-11  2.146172e-10  4.451442e-10   \n",
       "1  1.188707e-09  3.779748e-10  2.234186e-10  6.680412e-10  6.218913e-09   \n",
       "2  6.123937e-08  8.660994e-08  1.589899e-07  6.396412e-08  4.406861e-08   \n",
       "3  4.613280e-08  2.906938e-08  3.552248e-08  5.806047e-08  4.948989e-08   \n",
       "4  5.341250e-09  2.156079e-08  3.660990e-08  8.600722e-09  5.131207e-09   \n",
       "\n",
       "              5             6             7             8             9  ...  \\\n",
       "0  4.280263e-10  2.788707e-10  1.879692e-09  1.174269e-09  4.461908e-10  ...   \n",
       "1  1.137445e-08  2.683028e-09  5.531596e-09  8.906017e-09  6.461679e-09  ...   \n",
       "2  6.402577e-08  5.034104e-08  7.215107e-08  2.666949e-08  1.086904e-08  ...   \n",
       "3  5.540470e-08  2.852813e-08  3.038411e-08  4.256698e-08  2.405028e-08  ...   \n",
       "4  4.675287e-09  2.080450e-09  2.264334e-09  1.884883e-09  2.813915e-09  ...   \n",
       "\n",
       "            122           123           124           125           126  \\\n",
       "0  3.662752e-08  8.307025e-08  9.287401e-08  3.056497e-08  4.678518e-09   \n",
       "1  2.217372e-08  3.826104e-09  1.010611e-09  7.145892e-10  3.149462e-10   \n",
       "2  1.322439e-09  1.381340e-09  1.323247e-10  2.768844e-11  1.122044e-09   \n",
       "3  1.889469e-09  1.447878e-08  4.330400e-08  7.822125e-08  3.754572e-08   \n",
       "4  2.316695e-07  8.649530e-08  1.058607e-07  8.464285e-08  6.483439e-08   \n",
       "\n",
       "            127           128           129  Gender  Emotion  \n",
       "0  5.241251e-09  6.313334e-09  7.005036e-09    male  neutral  \n",
       "1  2.505838e-10  1.273010e-10  1.725840e-10    male  neutral  \n",
       "2  1.865057e-09  4.243676e-10  4.917393e-10    male  neutral  \n",
       "3  1.115205e-08  9.865569e-09  2.300178e-08    male  neutral  \n",
       "4  5.629305e-08  3.093712e-08  4.056278e-08    male     calm  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For splitting the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For scaling the data as necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For doing principal component analysis as necessary\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For building a variety of models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For hyperparameter optimization\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For caching pipeline and grid search results\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For getting rid of warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading in the finished dataframe from part 1\n",
    "df = pd.read_csv('C:/Users/Patrick/Documents/Capstone Data/ravdess_mel_no_offset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Gender (Regardless of Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "X = df.iloc[:, :-2]\n",
    "g = df['Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention is to name the target variable 'y', but I will be declaring many different target variables throughout the notebook, so I opted for 'g' for simplicity instead of 'y_g' or 'y_gen', for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, g_train, g_test = train_test_split(X, g, test_size=0.3, stratify=g, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 130)\n",
      "(432, 130)\n",
      "(1006,)\n",
      "(432,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(g_train.shape)\n",
    "print(g_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to build a simple, initial classifier to get a sense of the performances I might get in more optimized models. To this end, I will build a logistic regression model without doing any cross-validation or hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 67.49502982107356%\n",
      "Model accuracy on test set: 61.80555555555556%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg.fit(X_train, g_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg.score(X_train, g_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg.score(X_test, g_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only male recordings\n",
    "male_df = df[df['Gender'] == 'male'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xm = male_df.iloc[:, :-2]\n",
    "em = male_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xm_train, Xm_test, em_train, em_test = train_test_split(Xm, em, test_size=0.3, stratify=em, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 130)\n",
      "(216, 130)\n",
      "(502,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xm_train.shape)\n",
    "print(Xm_test.shape)\n",
    "print(em_train.shape)\n",
    "print(em_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, I will try building an initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 43.42629482071713%\n",
      "Model accuracy on test set: 26.38888888888889%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_em = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_em.fit(Xm_train, em_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_em.score(Xm_train, em_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_em.score(Xm_test, em_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                   10               2                    3   \n",
       "Actual calm                     0              24                    1   \n",
       "Actual disgusted                1              12                    8   \n",
       "Actual fearful                  4               4                    6   \n",
       "Actual happy                    5               9                    6   \n",
       "Actual neutral                  0              11                    2   \n",
       "Actual sad                      1              21                    2   \n",
       "Actual surprised                1              12                    2   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      4                6                  0   \n",
       "Actual calm                       1                0                  0   \n",
       "Actual disgusted                  2                1                  0   \n",
       "Actual fearful                    7                3                  0   \n",
       "Actual happy                      1                2                  0   \n",
       "Actual neutral                    0                0                  0   \n",
       "Actual sad                        0                3                  0   \n",
       "Actual surprised                  5                2                  0   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  2                    2  \n",
       "Actual calm                   2                    0  \n",
       "Actual disgusted              3                    2  \n",
       "Actual fearful                0                    5  \n",
       "Actual happy                  2                    4  \n",
       "Actual neutral                1                    0  \n",
       "Actual sad                    0                    2  \n",
       "Actual surprised              1                    6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_em make predictions based on the test set features\n",
    "em_pred = initial_logreg_em.predict(Xm_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "em_confusion_df = pd.DataFrame(confusion_matrix(em_test, em_pred))\n",
    "em_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "em_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "em_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.45      0.34      0.39        29\n",
      "        calm       0.25      0.86      0.39        28\n",
      "   disgusted       0.27      0.28      0.27        29\n",
      "     fearful       0.35      0.24      0.29        29\n",
      "       happy       0.12      0.07      0.09        29\n",
      "     neutral       0.00      0.00      0.00        14\n",
      "         sad       0.00      0.00      0.00        29\n",
      "   surprised       0.29      0.21      0.24        29\n",
      "\n",
      "    accuracy                           0.26       216\n",
      "   macro avg       0.22      0.25      0.21       216\n",
      "weighted avg       0.23      0.26      0.22       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(em_test, em_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train\n",
    "pca = PCA().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_pca = pca.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_pca = pca.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xm_train\n",
    "scaler = StandardScaler().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_scaled = scaler.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_scaled = scaler.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train_scaled\n",
    "pca_scaled = PCA().fit(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_train_scaled\n",
    "Xm_train_scaled_pca = pca_scaled.transform(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_test_scaled\n",
    "Xm_test_scaled_pca = pca_scaled.transform(Xm_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8.735405e-07</td>\n",
       "      <td>2.097360e-07</td>\n",
       "      <td>1.894721e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.040114e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805326</td>\n",
       "      <td>1.208198</td>\n",
       "      <td>1.42238</td>\n",
       "      <td>2.247925</td>\n",
       "      <td>3.392157</td>\n",
       "      <td>3.079779</td>\n",
       "      <td>2.663571</td>\n",
       "      <td>3.12562</td>\n",
       "      <td>3.651693</td>\n",
       "      <td>4.031667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1             2             3             4         5  \\\n",
       "0  0.000003  0.000003  8.735405e-07  2.097360e-07  1.894721e-07  0.000005   \n",
       "\n",
       "          6         7         8             9  ...       120       121  \\\n",
       "0  0.000008  0.000004  0.000002  3.040114e-07  ...  1.805326  1.208198   \n",
       "\n",
       "       122       123       124       125       126      127       128  \\\n",
       "0  1.42238  2.247925  3.392157  3.079779  2.663571  3.12562  3.651693   \n",
       "\n",
       "        129  \n",
       "0  4.031667  \n",
       "\n",
       "[1 rows x 130 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining the variances\n",
    "var_df = pd.DataFrame(male_df.var()).T\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 30 unscaled principal components: 99.69%\n",
      "Variance explained by 20 unscaled principal components: 98.59%\n",
      "Variance explained by 15 unscaled principal components: 97.09%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 30 scaled principal components: 97.69%\n",
      "Variance explained by 20 scaled principal components: 92.52%\n",
      "Variance explained by 15 scaled principal components: 86.46%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Pipeline (these values are placeholders)\n",
    "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('dim_reducer', PCA()), ('model', LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for log reg\n",
    "logreg_param_grid = [\n",
    "    # l1 without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(penalty='l1', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l1 with PCA\n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30],\n",
    "     'model': [LogisticRegression(penalty='l1', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) with PCA\n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30],\n",
    "     'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the log reg grid search\n",
    "logreg_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 713 out of 720 | elapsed:  7.8min remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  8.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_em = logreg_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                    random_state=None, solver='lbfgs',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 34.462151394422314%\n",
      "The best log reg's accuracy on the test set: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for SVM\n",
    "svm_param_grid = [\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [SVC()], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [SVC()],\n",
    "     'model__C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the SVM grid search\n",
    "svm_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_em = svm_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 56.573705179282875%\n",
      "The best SVM's accuracy on the test set: 28.703703703703702%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for KNN\n",
    "knn_param_grid = [\n",
    "    # unscaled and scaled * 10 Ks = 20 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [KNeighborsClassifier(n_jobs=-1)], 'model__n_neighbors': np.arange(3, 22, 2)},\n",
    "    \n",
    "    # unscaled and scaled * 3 PCAs * 10 Ks = 60 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "     'model__n_neighbors': np.arange(3, 22, 2)}\n",
    "]\n",
    "\n",
    "# Instantiate the grid search\n",
    "knn_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   12.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=11, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 42.82868525896414%\n",
      "The best KNN model's accuracy on the test set: 30.09259259259259%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for random forest (scaling is unnecessary)\n",
    "rf_param_grid = [\n",
    "    # 5 numbers of estimators * 5 max depths = 25 models\n",
    "    {'scaler': [None], 'dim_reducer': [None], 'model': [RandomForestClassifier(n_jobs=-1)], 'model__n_estimators': np.arange(100, 501, 100),\n",
    "     'model__max_depth': np.arange(5, 26, 5)},\n",
    "    \n",
    "    # 3 PCAs * 5 numbers of estimators * 5 max depths = 75 models\n",
    "    {'scaler': [None], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [RandomForestClassifier(n_jobs=-1)],\n",
    "     'model__n_estimators': np.arange(100, 501, 100), 'model__max_depth': np.arange(5, 26, 5)}\n",
    "]\n",
    "\n",
    "# Instantiate the rf grid search\n",
    "rf_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=25,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 43.98148148148148%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only female recordings\n",
    "female_df = df[df['Gender'] == 'female'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xf = female_df.iloc[:, :-2]\n",
    "ef = female_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xf_train, Xf_test, ef_train, ef_test = train_test_split(Xf, ef, test_size=0.3, stratify=ef, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 130)\n",
      "(216, 130)\n",
      "(504,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xf_train.shape)\n",
    "print(Xf_test.shape)\n",
    "print(ef_train.shape)\n",
    "print(ef_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 46.42857142857143%\n",
      "Model accuracy on test set: 32.870370370370374%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_ef = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_ef.fit(Xf_train, ef_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_ef.score(Xf_train, ef_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_ef.score(Xf_test, ef_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                   11               1                    4   \n",
       "Actual calm                     0              27                    0   \n",
       "Actual disgusted                1              13                   12   \n",
       "Actual fearful                  2               3                    6   \n",
       "Actual happy                    3               4                    2   \n",
       "Actual neutral                  0              13                    1   \n",
       "Actual sad                      5              21                    1   \n",
       "Actual surprised                2               7                    0   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      2                6                  0   \n",
       "Actual calm                       0                2                  0   \n",
       "Actual disgusted                  0                0                  0   \n",
       "Actual fearful                    4                5                  0   \n",
       "Actual happy                      2                5                  0   \n",
       "Actual neutral                    0                0                  0   \n",
       "Actual sad                        0                1                  0   \n",
       "Actual surprised                  3                2                  0   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  0                    5  \n",
       "Actual calm                   0                    0  \n",
       "Actual disgusted              3                    0  \n",
       "Actual fearful                2                    7  \n",
       "Actual happy                  4                    9  \n",
       "Actual neutral                0                    0  \n",
       "Actual sad                    1                    0  \n",
       "Actual surprised              3                   11  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_ef make predictions based on the test set features\n",
    "ef_pred = initial_logreg_ef.predict(Xf_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "ef_confusion_df = pd.DataFrame(confusion_matrix(ef_test, ef_pred))\n",
    "ef_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "ef_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "ef_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.38      0.42        29\n",
      "        calm       0.30      0.93      0.46        29\n",
      "   disgusted       0.46      0.41      0.44        29\n",
      "     fearful       0.36      0.14      0.20        29\n",
      "       happy       0.24      0.17      0.20        29\n",
      "     neutral       0.00      0.00      0.00        14\n",
      "         sad       0.08      0.03      0.05        29\n",
      "   surprised       0.34      0.39      0.37        28\n",
      "\n",
      "    accuracy                           0.33       216\n",
      "   macro avg       0.28      0.31      0.27       216\n",
      "weighted avg       0.30      0.33      0.28       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(ef_test, ef_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train\n",
    "pca = PCA().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_pca = pca.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_pca = pca.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xf_train\n",
    "scaler = StandardScaler().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_scaled = scaler.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_scaled = scaler.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train_scaled\n",
    "pca_scaled = PCA().fit(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_train_scaled\n",
    "Xf_train_scaled_pca = pca_scaled.transform(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_test_scaled\n",
    "Xf_test_scaled_pca = pca_scaled.transform(Xf_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 30 unscaled principal components: 99.27%\n",
      "Variance explained by 20 unscaled principal components: 97.06%\n",
      "Variance explained by 15 unscaled principal components: 94.08%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 30 scaled principal components: 96.76%\n",
      "Variance explained by 20 scaled principal components: 91.26%\n",
      "Variance explained by 15 scaled principal components: 85.32%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, I will now do a grid search for each classifier type, with five-fold cross-validation to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 323 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 623 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 10.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_ef = logreg_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=10000, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 39.88095238095239%\n",
      "The best log reg's accuracy on the test set: 31.944444444444443%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    8.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_ef = svm_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 77.97619047619048%\n",
      "The best SVM's accuracy on the test set: 36.11111111111111%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   13.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=11, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 42.82868525896414%\n",
      "The best KNN model's accuracy on the test set: 30.09259259259259%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsxf5muqb',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=300, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 43.98148148148148%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
