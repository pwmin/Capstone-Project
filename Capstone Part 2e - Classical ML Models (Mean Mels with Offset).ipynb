{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Part 2e - Classical ML Models (Mean Mels with Offset)\n",
    "___\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.533443e-10</td>\n",
       "      <td>4.470215e-11</td>\n",
       "      <td>8.070570e-11</td>\n",
       "      <td>2.146172e-10</td>\n",
       "      <td>4.451442e-10</td>\n",
       "      <td>4.280263e-10</td>\n",
       "      <td>2.788707e-10</td>\n",
       "      <td>1.879692e-09</td>\n",
       "      <td>1.174269e-09</td>\n",
       "      <td>4.461908e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.662752e-08</td>\n",
       "      <td>8.307025e-08</td>\n",
       "      <td>9.287401e-08</td>\n",
       "      <td>3.056497e-08</td>\n",
       "      <td>4.678518e-09</td>\n",
       "      <td>5.241251e-09</td>\n",
       "      <td>6.313334e-09</td>\n",
       "      <td>7.005036e-09</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.188707e-09</td>\n",
       "      <td>3.779748e-10</td>\n",
       "      <td>2.234186e-10</td>\n",
       "      <td>6.680412e-10</td>\n",
       "      <td>6.218913e-09</td>\n",
       "      <td>1.137445e-08</td>\n",
       "      <td>2.683028e-09</td>\n",
       "      <td>5.531596e-09</td>\n",
       "      <td>8.906017e-09</td>\n",
       "      <td>6.461679e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217372e-08</td>\n",
       "      <td>3.826104e-09</td>\n",
       "      <td>1.010611e-09</td>\n",
       "      <td>7.145892e-10</td>\n",
       "      <td>3.149462e-10</td>\n",
       "      <td>2.505838e-10</td>\n",
       "      <td>1.273010e-10</td>\n",
       "      <td>1.725840e-10</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.123937e-08</td>\n",
       "      <td>8.660994e-08</td>\n",
       "      <td>1.589899e-07</td>\n",
       "      <td>6.396412e-08</td>\n",
       "      <td>4.406861e-08</td>\n",
       "      <td>6.402577e-08</td>\n",
       "      <td>5.034104e-08</td>\n",
       "      <td>7.215107e-08</td>\n",
       "      <td>2.666949e-08</td>\n",
       "      <td>1.086904e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.322439e-09</td>\n",
       "      <td>1.381340e-09</td>\n",
       "      <td>1.323247e-10</td>\n",
       "      <td>2.768844e-11</td>\n",
       "      <td>1.122044e-09</td>\n",
       "      <td>1.865057e-09</td>\n",
       "      <td>4.243676e-10</td>\n",
       "      <td>4.917393e-10</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.613280e-08</td>\n",
       "      <td>2.906938e-08</td>\n",
       "      <td>3.552248e-08</td>\n",
       "      <td>5.806047e-08</td>\n",
       "      <td>4.948989e-08</td>\n",
       "      <td>5.540470e-08</td>\n",
       "      <td>2.852813e-08</td>\n",
       "      <td>3.038411e-08</td>\n",
       "      <td>4.256698e-08</td>\n",
       "      <td>2.405028e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.889469e-09</td>\n",
       "      <td>1.447878e-08</td>\n",
       "      <td>4.330400e-08</td>\n",
       "      <td>7.822125e-08</td>\n",
       "      <td>3.754572e-08</td>\n",
       "      <td>1.115205e-08</td>\n",
       "      <td>9.865569e-09</td>\n",
       "      <td>2.300178e-08</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.184508e-11</td>\n",
       "      <td>2.776947e-10</td>\n",
       "      <td>2.597032e-10</td>\n",
       "      <td>1.652612e-10</td>\n",
       "      <td>2.990570e-10</td>\n",
       "      <td>2.350421e-10</td>\n",
       "      <td>9.289343e-10</td>\n",
       "      <td>5.398018e-10</td>\n",
       "      <td>2.240118e-11</td>\n",
       "      <td>2.210581e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.282968e-10</td>\n",
       "      <td>2.595139e-09</td>\n",
       "      <td>2.578465e-09</td>\n",
       "      <td>4.286336e-10</td>\n",
       "      <td>1.172365e-09</td>\n",
       "      <td>9.211989e-10</td>\n",
       "      <td>1.238382e-09</td>\n",
       "      <td>4.182768e-10</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  1.533443e-10  4.470215e-11  8.070570e-11  2.146172e-10  4.451442e-10   \n",
       "1  1.188707e-09  3.779748e-10  2.234186e-10  6.680412e-10  6.218913e-09   \n",
       "2  6.123937e-08  8.660994e-08  1.589899e-07  6.396412e-08  4.406861e-08   \n",
       "3  4.613280e-08  2.906938e-08  3.552248e-08  5.806047e-08  4.948989e-08   \n",
       "4  2.184508e-11  2.776947e-10  2.597032e-10  1.652612e-10  2.990570e-10   \n",
       "\n",
       "              5             6             7             8             9  ...  \\\n",
       "0  4.280263e-10  2.788707e-10  1.879692e-09  1.174269e-09  4.461908e-10  ...   \n",
       "1  1.137445e-08  2.683028e-09  5.531596e-09  8.906017e-09  6.461679e-09  ...   \n",
       "2  6.402577e-08  5.034104e-08  7.215107e-08  2.666949e-08  1.086904e-08  ...   \n",
       "3  5.540470e-08  2.852813e-08  3.038411e-08  4.256698e-08  2.405028e-08  ...   \n",
       "4  2.350421e-10  9.289343e-10  5.398018e-10  2.240118e-11  2.210581e-10  ...   \n",
       "\n",
       "            122           123           124           125           126  \\\n",
       "0  3.662752e-08  8.307025e-08  9.287401e-08  3.056497e-08  4.678518e-09   \n",
       "1  2.217372e-08  3.826104e-09  1.010611e-09  7.145892e-10  3.149462e-10   \n",
       "2  1.322439e-09  1.381340e-09  1.323247e-10  2.768844e-11  1.122044e-09   \n",
       "3  1.889469e-09  1.447878e-08  4.330400e-08  7.822125e-08  3.754572e-08   \n",
       "4  9.282968e-10  2.595139e-09  2.578465e-09  4.286336e-10  1.172365e-09   \n",
       "\n",
       "            127           128           129  Gender  Emotion  \n",
       "0  5.241251e-09  6.313334e-09  7.005036e-09    male  neutral  \n",
       "1  2.505838e-10  1.273010e-10  1.725840e-10    male  neutral  \n",
       "2  1.865057e-09  4.243676e-10  4.917393e-10    male  neutral  \n",
       "3  1.115205e-08  9.865569e-09  2.300178e-08    male  neutral  \n",
       "4  9.211989e-10  1.238382e-09  4.182768e-10    male     calm  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For splitting the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For scaling the data as necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For doing principal component analysis as necessary\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For building a variety of models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For hyperparameter optimization\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For caching pipeline and grid search results\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For getting rid of warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading in the finished dataframe from part 1\n",
    "df = pd.read_csv('C:/Users/Patrick/Documents/Capstone Data/ravdess_mel_offset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Gender (Regardless of Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "X = df.iloc[:, :-2]\n",
    "g = df['Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention is to name the target variable 'y', but I will be declaring many different target variables throughout the notebook, so I opted for 'g' for simplicity instead of 'y_g' or 'y_gen', for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, g_train, g_test = train_test_split(X, g, test_size=0.3, stratify=g, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 130)\n",
      "(432, 130)\n",
      "(1006,)\n",
      "(432,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(g_train.shape)\n",
    "print(g_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to build a simple, initial classifier to get a sense of the performances I might get in more optimized models. To this end, I will build a logistic regression model without doing any cross-validation or hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 66.30218687872762%\n",
      "Model accuracy on test set: 62.96296296296296%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg.fit(X_train, g_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg.score(X_train, g_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg.score(X_test, g_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only male recordings\n",
    "male_df = df[df['Gender'] == 'male'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xm = male_df.iloc[:, :-2]\n",
    "em = male_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xm_train, Xm_test, em_train, em_test = train_test_split(Xm, em, test_size=0.3, stratify=em, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 130)\n",
      "(216, 130)\n",
      "(502,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xm_train.shape)\n",
    "print(Xm_test.shape)\n",
    "print(em_train.shape)\n",
    "print(em_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, I will try building an initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 45.21912350597609%\n",
      "Model accuracy on test set: 27.314814814814813%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_em = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_em.fit(Xm_train, em_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_em.score(Xm_train, em_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_em.score(Xm_test, em_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                   13               2                    0   \n",
       "Actual calm                     0              24                    1   \n",
       "Actual disgusted                1              13                    7   \n",
       "Actual fearful                  5               5                    1   \n",
       "Actual happy                    3               9                    3   \n",
       "Actual neutral                  0              10                    1   \n",
       "Actual sad                      2              22                    1   \n",
       "Actual surprised                0              12                    2   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      5                3                  0   \n",
       "Actual calm                       0                1                  0   \n",
       "Actual disgusted                  2                1                  0   \n",
       "Actual fearful                    4                5                  0   \n",
       "Actual happy                      2                6                  0   \n",
       "Actual neutral                    0                0                  0   \n",
       "Actual sad                        0                2                  0   \n",
       "Actual surprised                  2                8                  0   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  3                    3  \n",
       "Actual calm                   2                    0  \n",
       "Actual disgusted              3                    2  \n",
       "Actual fearful                2                    7  \n",
       "Actual happy                  3                    3  \n",
       "Actual neutral                1                    2  \n",
       "Actual sad                    1                    1  \n",
       "Actual surprised              1                    4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_em make predictions based on the test set features\n",
    "em_pred = initial_logreg_em.predict(Xm_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "em_confusion_df = pd.DataFrame(confusion_matrix(em_test, em_pred))\n",
    "em_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "em_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "em_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.45      0.49        29\n",
      "        calm       0.25      0.86      0.38        28\n",
      "   disgusted       0.44      0.24      0.31        29\n",
      "     fearful       0.27      0.14      0.18        29\n",
      "       happy       0.23      0.21      0.22        29\n",
      "     neutral       0.00      0.00      0.00        14\n",
      "         sad       0.06      0.03      0.04        29\n",
      "   surprised       0.18      0.14      0.16        29\n",
      "\n",
      "    accuracy                           0.27       216\n",
      "   macro avg       0.25      0.26      0.22       216\n",
      "weighted avg       0.26      0.27      0.24       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(em_test, em_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train\n",
    "pca = PCA().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_pca = pca.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_pca = pca.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xm_train\n",
    "scaler = StandardScaler().fit(Xm_train)\n",
    "\n",
    "# Transform Xm_train\n",
    "Xm_train_scaled = scaler.transform(Xm_train)\n",
    "\n",
    "# Transform Xm_test\n",
    "Xm_test_scaled = scaler.transform(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xm_train_scaled\n",
    "pca_scaled = PCA().fit(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_train_scaled\n",
    "Xm_train_scaled_pca = pca_scaled.transform(Xm_train_scaled)\n",
    "\n",
    "# Transform Xm_test_scaled\n",
    "Xm_test_scaled_pca = pca_scaled.transform(Xm_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.270101e-07</td>\n",
       "      <td>1.731025e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114849</td>\n",
       "      <td>0.17577</td>\n",
       "      <td>0.278263</td>\n",
       "      <td>0.107821</td>\n",
       "      <td>0.055318</td>\n",
       "      <td>0.085634</td>\n",
       "      <td>0.141539</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.075233</td>\n",
       "      <td>0.070858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000001  0.000003  0.000001  0.000019  0.000186  0.000318  0.000042   \n",
       "\n",
       "          7             8             9  ...       120      121       122  \\\n",
       "0  0.000005  5.270101e-07  1.731025e-07  ...  0.114849  0.17577  0.278263   \n",
       "\n",
       "        123       124       125       126       127       128       129  \n",
       "0  0.107821  0.055318  0.085634  0.141539  0.094595  0.075233  0.070858  \n",
       "\n",
       "[1 rows x 130 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining the variances\n",
    "var_df = pd.DataFrame(male_df.var()).T\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 30 unscaled principal components: 99.58%\n",
      "Variance explained by 20 unscaled principal components: 98.29%\n",
      "Variance explained by 15 unscaled principal components: 96.66%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 30 scaled principal components: 98.41%\n",
      "Variance explained by 20 scaled principal components: 94.46%\n",
      "Variance explained by 15 scaled principal components: 89.31%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Pipeline (these values are placeholders)\n",
    "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('dim_reducer', PCA()), ('model', LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for log reg\n",
    "logreg_param_grid = [\n",
    "    # l1 without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(penalty='l1', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l1 with PCA\n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30],\n",
    "     'model': [LogisticRegression(penalty='l1', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) without PCA\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)],\n",
    "     'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # l2 (default) with PCA\n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30],\n",
    "     'model': [LogisticRegression(solver='lbfgs', n_jobs=-1)], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the log reg grid search\n",
    "logreg_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 339 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 517 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 10.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_em = logreg_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=20,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 34.06374501992032%\n",
      "The best log reg's accuracy on the test set: 26.851851851851855%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for SVM\n",
    "svm_param_grid = [\n",
    "    # unscaled and scaled * 9 regularization strengths = 18 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [SVC()], 'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
    "    \n",
    "    # unscaled and scaled * 3 PCAs * 9 regularization strengths = 54 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [SVC()],\n",
    "     'model__C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "]\n",
    "\n",
    "# Instantiate the SVM grid search\n",
    "svm_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    8.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_em = svm_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=30,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 66.93227091633466%\n",
      "The best SVM's accuracy on the test set: 32.407407407407405%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for KNN\n",
    "knn_param_grid = [\n",
    "    # unscaled and scaled * 10 Ks = 20 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [None], 'model': [KNeighborsClassifier(n_jobs=-1)], 'model__n_neighbors': np.arange(3, 22, 2)},\n",
    "    \n",
    "    # unscaled and scaled * 3 PCAs * 10 Ks = 60 models\n",
    "    {'scaler': [None, StandardScaler()], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "     'model__n_neighbors': np.arange(3, 22, 2)}\n",
    "]\n",
    "\n",
    "# Instantiate the grid search\n",
    "knn_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   15.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=3, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 61.15537848605578%\n",
      "The best KNN model's accuracy on the test set: 30.555555555555557%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for random forest (scaling is unnecessary)\n",
    "rf_param_grid = [\n",
    "    # 5 numbers of estimators * 5 max depths = 25 models\n",
    "    {'scaler': [None], 'dim_reducer': [None], 'model': [RandomForestClassifier(n_jobs=-1)], 'model__n_estimators': np.arange(100, 501, 100),\n",
    "     'model__max_depth': np.arange(5, 26, 5)},\n",
    "    \n",
    "    # 3 PCAs * 5 numbers of estimators * 5 max depths = 75 models\n",
    "    {'scaler': [None], 'dim_reducer': [PCA()], 'dim_reducer__n_components': [15, 20, 30], 'model': [RandomForestClassifier(n_jobs=-1)],\n",
    "     'model__n_estimators': np.arange(100, 501, 100), 'model__max_depth': np.arange(5, 26, 5)}\n",
    "]\n",
    "\n",
    "# Instantiate the rf grid search\n",
    "rf_grid_search = GridSearchCV(estimator=my_pipeline, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 42.129629629629626%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Building Models for Classifying Emotion for Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe that contains only female recordings\n",
    "female_df = df[df['Gender'] == 'female'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into features and target\n",
    "Xf = female_df.iloc[:, :-2]\n",
    "ef = female_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "Xf_train, Xf_test, ef_train, ef_test = train_test_split(Xf, ef, test_size=0.3, stratify=ef, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 130)\n",
      "(216, 130)\n",
      "(504,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shapes\n",
    "print(Xf_train.shape)\n",
    "print(Xf_test.shape)\n",
    "print(ef_train.shape)\n",
    "print(ef_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training set: 46.62698412698413%\n",
      "Model accuracy on test set: 31.944444444444443%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "initial_logreg_ef = LogisticRegression()\n",
    "\n",
    "# Fit to training set\n",
    "initial_logreg_ef.fit(Xf_train, ef_train)\n",
    "\n",
    "# Score on training set\n",
    "print(f'Model accuracy on training set: {initial_logreg_ef.score(Xf_train, ef_train)*100}%')\n",
    "\n",
    "# Score on test set\n",
    "print(f'Model accuracy on test set: {initial_logreg_ef.score(Xf_test, ef_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted angry</th>\n",
       "      <th>Predicted calm</th>\n",
       "      <th>Predicted disgusted</th>\n",
       "      <th>Predicted fearful</th>\n",
       "      <th>Predicted happy</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted sad</th>\n",
       "      <th>Predicted surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual angry</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual calm</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual disgusted</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual fearful</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual happy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual sad</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual surprised</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted angry  Predicted calm  Predicted disgusted  \\\n",
       "Actual angry                   10               2                    2   \n",
       "Actual calm                     0              27                    0   \n",
       "Actual disgusted                0              14                   11   \n",
       "Actual fearful                  4               2                    3   \n",
       "Actual happy                    4               4                    3   \n",
       "Actual neutral                  0              13                    0   \n",
       "Actual sad                      5              22                    0   \n",
       "Actual surprised                1               7                    0   \n",
       "\n",
       "                  Predicted fearful  Predicted happy  Predicted neutral  \\\n",
       "Actual angry                      2                3                  0   \n",
       "Actual calm                       0                1                  0   \n",
       "Actual disgusted                  0                0                  0   \n",
       "Actual fearful                    4                4                  0   \n",
       "Actual happy                      4                3                  0   \n",
       "Actual neutral                    0                0                  0   \n",
       "Actual sad                        0                1                  0   \n",
       "Actual surprised                  2                2                  0   \n",
       "\n",
       "                  Predicted sad  Predicted surprised  \n",
       "Actual angry                  1                    9  \n",
       "Actual calm                   0                    1  \n",
       "Actual disgusted              2                    2  \n",
       "Actual fearful                4                    8  \n",
       "Actual happy                  4                    7  \n",
       "Actual neutral                0                    1  \n",
       "Actual sad                    1                    0  \n",
       "Actual surprised              3                   13  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having initial_logreg_ef make predictions based on the test set features\n",
    "ef_pred = initial_logreg_ef.predict(Xf_test)\n",
    "\n",
    "# Building the confusion matrix as a dataframe\n",
    "emotions = ['angry', 'calm', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
    "ef_confusion_df = pd.DataFrame(confusion_matrix(ef_test, ef_pred))\n",
    "ef_confusion_df.columns = [f'Predicted {emotion}' for emotion in emotions]\n",
    "ef_confusion_df.index = [f'Actual {emotion}' for emotion in emotions]\n",
    "ef_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.42      0.34      0.38        29\n",
      "        calm       0.30      0.93      0.45        29\n",
      "   disgusted       0.58      0.38      0.46        29\n",
      "     fearful       0.33      0.14      0.20        29\n",
      "       happy       0.21      0.10      0.14        29\n",
      "     neutral       0.00      0.00      0.00        14\n",
      "         sad       0.07      0.03      0.05        29\n",
      "   surprised       0.32      0.46      0.38        28\n",
      "\n",
      "    accuracy                           0.32       216\n",
      "   macro avg       0.28      0.30      0.26       216\n",
      "weighted avg       0.30      0.32      0.27       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(ef_test, ef_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on unscaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train\n",
    "pca = PCA().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_pca = pca.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_pca = pca.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# Instantiate the scaler and fit to Xf_train\n",
    "scaler = StandardScaler().fit(Xf_train)\n",
    "\n",
    "# Transform Xf_train\n",
    "Xf_train_scaled = scaler.transform(Xf_train)\n",
    "\n",
    "# Transform Xf_test\n",
    "Xf_test_scaled = scaler.transform(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled features\n",
    "\n",
    "# Instantiate PCA and fit to Xf_train_scaled\n",
    "pca_scaled = PCA().fit(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_train_scaled\n",
    "Xf_train_scaled_pca = pca_scaled.transform(Xf_train_scaled)\n",
    "\n",
    "# Transform Xf_test_scaled\n",
    "Xf_test_scaled_pca = pca_scaled.transform(Xf_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the explained variance ratios\n",
    "\n",
    "plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "# Unscaled\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Unscaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "# Scaled\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(1, len(pca_scaled.explained_variance_ratio_)+1), pca_scaled.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA on Scaled Features')\n",
    "plt.ylim(top = 0.6) # Equalizing the y-axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance is explained by certain numbers of unscaled and scaled principal components? This will help me determine how many principal components to try in my grid searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 unscaled principal components: 100.0%\n",
      "Variance explained by 30 unscaled principal components: 99.07%\n",
      "Variance explained by 20 unscaled principal components: 96.72%\n",
      "Variance explained by 15 unscaled principal components: 93.56%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} unscaled principal components: {np.round(np.sum(pca.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by 130 scaled principal components: 100.0%\n",
      "Variance explained by 30 scaled principal components: 96.31%\n",
      "Variance explained by 20 scaled principal components: 90.65%\n",
      "Variance explained by 15 scaled principal components: 84.21%\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "num_components = [131, 31, 21, 16]\n",
    "for n in num_components:\n",
    "    print(f'Variance explained by {n-1} scaled principal components: {np.round(np.sum(pca_scaled.explained_variance_ratio_[:n])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, I will now do a grid search for each classifier type, with five-fold cross-validation to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 11.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the log reg grid search\n",
    "fitted_logreg_grid_ef = logreg_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=20,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=100, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best log reg?\n",
    "fitted_logreg_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best log reg's accuracy on the training set: 41.07142857142857%\n",
      "The best log reg's accuracy on the test set: 33.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best log reg's accuracy on the training set: {fitted_logreg_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best log reg's accuracy on the test set: {fitted_logreg_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   14.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM grid search\n",
    "fitted_svm_grid_ef = svm_grid_search.fit(Xf_train, ef_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=30,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best SVM?\n",
    "fitted_svm_grid_ef.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM's accuracy on the training set: 78.17460317460318%\n",
      "The best SVM's accuracy on the test set: 34.72222222222222%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best SVM's accuracy on the training set: {fitted_svm_grid_ef.score(Xf_train, ef_train)*100}%\")\n",
    "print(f\"The best SVM's accuracy on the test set: {fitted_svm_grid_ef.score(Xf_test, ef_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the KNN grid search\n",
    "fitted_knn_grid_em = knn_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None),\n",
       "                ('dim_reducer',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=15,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=3, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best KNN model?\n",
    "fitted_knn_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN model's accuracy on the training set: 61.15537848605578%\n",
      "The best KNN model's accuracy on the test set: 30.555555555555557%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best KNN model's accuracy on the training set: {fitted_knn_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best KNN model's accuracy on the test set: {fitted_knn_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf grid search\n",
    "fitted_rf_grid_em = rf_grid_search.fit(Xm_train, em_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\Patrick\\\\AppData\\\\Local\\\\Temp\\\\tmpsg6220ix',\n",
       "         steps=[('scaler', None), ('dim_reducer', None),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=500, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the best rf?\n",
    "fitted_rf_grid_em.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest's accuracy on the training set: 100.0%\n",
      "The best random forest's accuracy on the test set: 40.74074074074074%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best random forest's accuracy on the training set: {fitted_rf_grid_em.score(Xm_train, em_train)*100}%\")\n",
    "print(f\"The best random forest's accuracy on the test set: {fitted_rf_grid_em.score(Xm_test, em_test)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
